# LazealCellist Documentation

# Logic of Lazeal Cellist Platform

![cellist.png](LazealCellist%20Documentation/cellist.png)

This model is indeed a form of structured Variational AutoEncoder (VAE) with Sequential Monte Carlo (SMC) elements. The overall structure can be represented as:

```
For each image:
    For each grid cell (i, j) in the image:
        For each object t in the cell:
            Sample presence of the object: z_pres[i,j,t] ~ Bernoulli(p)
            If z_pres[i,j,t] == 1:
                Sample position and size of the object: z_where[i,j,t] ~ Normal(mu, sigma)
                Sample appearance of the object: z_what[i,j,t] ~ Normal(mu, sigma)
                Generate image patch for the object: y[i,j,t] = Decoder(z_what[i,j,t])
            Combine the generated object with the existing image: x = x + z_pres[i,j,t] * SpatialTransformer(y[i,j,t], z_where[i,j,t])
    Observe the final image with some noise: x_obs ~ Normal(x, sigma)
```

In mathematical terms, the prior model is expressed as follows:

1. For the presence of objects, $z_{\text{pres}}[i,j,t]$:

$$
z_{\text{pres}}[i,j,t] \sim \text{Bernoulli}(p)
$$



1. For the position and size of objects, $z_{\text{where}}[i,j,t]$:

$$
z_{\text{where}}[i,j,t] \sim \text{Normal}(\mu_{\text{where}}, \sigma_{\text{where}})
$$



1. For the appearance of objects, $z_{\text{what}}[i,j,t]$:

$$
z_{\text{what}}[i,j,t] \sim \text{Normal}(\mu_{\text{what}}, \sigma_{\text{what}})
$$

1. The likelihood for the observed image is defined as:

$$
x_{\text{obs}} \sim \text{Normal}(x, \sigma_{\text{obs}})
$$

Where $x$ is the image generated by the model by combining the objects generated at each grid cell.

The guide (also known as the variational posterior or inference model) would typically mirror the structure of the model, but with the parameters of the distributions conditioned on the observed image. The details of the guide are not provided in your code snippet, but typically we'd have something like:

1. For the presence of objects, $z_{\text{pres}}[i,j,t]$:

$$
z_{\text{pres}}[i,j,t] \sim \text{Bernoulli}(p_{\text{pres}}(x_{\text{obs}}))
$$



1. For the position and size of objects, $z_{\text{where}}[i,j,t]$:

$$
z_{\text{where}}[i,j,t] \sim \text{Normal}(\mu_{\text{where}}(x_{\text{obs}}), \sigma_{\text{where}}(x_{\text{obs}}))
$$



1. For the appearance of objects, $z_{\text{what}}[i,j,t]$:

$$
z_{\text{what}}[i,j,t] \sim \text{Normal}(\mu_{\text{what}}(x_{\text{obs}}), \sigma_{\text{what}}(x_{\text{obs}}))
$$



Where $p*{\text{pres}}(x*{\text{obs}})$, $\mu*{\text{where}}(x*{\text{obs}})$, $\sigma*{\text{where}}(x*{\text{obs}})$, $\mu*{\text{what}}(x*{\text{obs}})$, and $\sigma*{\text{what}}(x*{\text{obs}})$ are functions parameterized by neural networks.

The goal of stochastic variational inference is to maximize the ELBO (Evidence Lower BOund), which is given by:

$$
\text{ELBO} = \mathbb{E}_{q(z|x_{\text{obs}})}[\log p(x_{\text{obs}}, z) - \log q(z|x_{\text{obs}})]
$$
Where $p(x*{\text{obs}}, z)$ is the joint probability of the observed data and the latent variables under the model, and $q(z|x*{\text{obs}})$ is the variational distribution that approximates the true posterior $p(z|x_{\text{obs}})$.

# TODO

## Polygon Sample: Use a polygon instead of a rectangle to annotate an object.

- Math

Absolutely. Let's write down the equation and explain it.

The core operation of the script is the computation of the "score" for each pixel in the image. This score is a measure of how far the pixel is from the edges of the polygon. The score is calculated using the cross product of the vectors from the pixel to each pair of vertices in the polygon.

The equation for calculating the score for a pixel at coordinates $(x*{xy}, y*{xy})$ is:

$$
\text{score}*{xy} = \sum*{i=1}^{N} \text{sign}\left( (x*{i} - x*{xy})(y*{i+1} - y*{i}) - (y*{i} - y*{xy})(x*{i+1} - x*{i}) \right)
$$

Where:

- $(x*{xy}, y*{xy})$ are the coordinates of the pixel.
- $(x*{i}, y*{i})$ and $(x*{i+1}, y*{i+1})$ are the coordinates of the i-th and (i+1)-th vertices of the polygon. The vertices are ordered in a counterclockwise manner around the polygon.
- $N$ is the number of vertices.
- The sign function returns -1 for negative numbers, 0 for zero, and 1 for positive numbers.

The score for each pixel is then normalized by subtracting the minimum score and dividing by the range of the scores (maximum score - minimum score). This normalized score is then used to generate the heat map image.

The equation for normalizing the scores is:

$$
\text{score}*{\text{norm}} = \frac{\text{score}*{xy} - \text{min}(\text{score})}{\text{max}(\text{score}) - \text{min}(\text{score})}
$$

Where:

- $\text{score}*{xy}$ is the score for the pixel at coordinates $(x*{xy}, y_{xy})$.
- $\text{min}(\text{score})$ and $\text{max}(\text{score})$ are the minimum and maximum scores over all pixels, respectively.
- $\text{score}_{\text{norm}}$ is the normalized score for the pixel.
- Code
  
    ```sql
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns
    
    x = np.arange(100)
    y = np.arange(100)
    xy = np.meshgrid(x, y)
    xy = np.stack(xy, axis=-1)
    
    # Define vertices of polygon
    vertices = np.array([[20, 60], [30, 40], [55, 20], [70, 20], [80, 25], [95, 35], [70, 60], [55, 70]])
    
    img = np.zeros((100, 100))
    
    # Set pixel values around the vertices
    for i,v in enumerate(vertices):
        img[v[1]-i-1:v[1]+i+1, v[0]-i-1:v[0]+i+1]= 1
    
    # Calculate mean position of vertices
    pos_mean = vertices.mean(axis=0, keepdims=True)
    pos_ = pos_mean.astype(int)
    img[pos_[0, 1], pos_[0, 0]] = 2
    
    plt.figure(dpi=100)
    plt.imshow(img)
    
    # Calculate direction of each vertex from mean position
    directions = vertices - pos_mean
    
    # Calculate angle of each direction
    angles = np.arctan2(directions[:, 0], directions[:, 1])
    
    # Sort vertices based on angles
    a = np.argsort(angles)[::-1]
    b = np.roll(a, -1)
    
    cross_ref = directions[a] * directions[b, ::-1] * np.array([[1, -1.]])
    cross_ref = cross_ref.sum(axis=-1)
    
    # Calculate score for each pixel
    score = vertices[:, None, None, :] - xy
    score = score[a] * score[b, :, :, ::-1] * np.array([1, -1])
    score = (np.sign(score.sum(axis=-1))).sum(0)
    
    # Normalize score to range between 0 and 1 using a form of softmax function
    score_exp = np.power(10., score)
    score_exp = (score_exp - score_exp.min()) / (score_exp.max() - score_exp.min())
    
    plt.figure(dpi=200)
    sns.histplot(score_exp.reshape(-1))
    
    plt.imshow(score_exp)
    ```
    
- Result
  
    ![polygon_sample.png](LazealCellist%20Documentation/polygon_sample.png)
    

## Optimize the model for **float32** data type, especially for these extremely small and large number occurred in calculation.

## Shrink the **model size** if possible.

## Upgrade the model for robust detection, like incorporating it with **transformer and stable diffusion.**

## Add base model option (Threshold, Cellpose) and target model option (AIR, Transformer, SD)

## Interface Optimization

- Multiple selection

## Backend Optimization

- Release GPT cache

## Easy-to-use package (using database without configuration)

- Sqlite

# Installation

## MySQL

### Make mysql accessible

You'll need to change the authentication method from `auth_socket` to `mysql_native_password` or `caching_sha2_password` (in MySQL 8.0 and above).

Here are the steps:

1. Log into MySQL without a password using sudo:

```bash
sudo mysql
```

1. Check the authentication method each MySQL user is using with the following command:

```sql
SELECT user,authentication_string,plugin,host FROM mysql.user;
```

1. If the `plugin` column for the `root` user is showing `auth_socket`, change the `root` user's plugin to `mysql_native_password` or `caching_sha2_password`:

```sql
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'yourpassword';
FLUSH PRIVILEGES;
EXIT;
```

### Restore Database

```sql
mysql -u root -p cellist < /home/user/cellist.sql
```

## Conda

```jsx
conda env create -f celist.yaml
```